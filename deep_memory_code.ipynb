{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the OpenAI key\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "activeloop_key = os.getenv(\"ACTIVELOOP_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAIChat\n",
    "from langchain.vectorstores.deeplake import DeepLake\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import random\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://siddartha10/manufacturing_CSI already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "# dataset_path = \"hub://101010/text_embedding\"\n",
    "# # Create a DeepLake instance and add the documents\n",
    "# db = DeepLake.from_documents(documents, dataset_path=dataset_path, embedding=OpenAIEmbeddings())\n",
    "\n",
    "db = DeepLake(\n",
    "    dataset_path=f\"hub://siddartha10/manufacturing_CSI\",  # org_id stands for your username or organization from activeloop\n",
    "    embedding=openai_embeddings,\n",
    "    runtime={\"tensor_db\": True},\n",
    "    token=activeloop_key,\n",
    "    # overwrite=True, # user overwrite flag if you want to overwrite the full dataset\n",
    "    read_only=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'file_paths' with the paths to your local PDF files\n",
    "file_paths = [\n",
    "    \"manual\\'s.pdf\",\n",
    "    \"Operation and Maintenance Manual.pdf\",\n",
    "    \"Operations Manual.pdf\"\n",
    "]\n",
    "# Initialize an empty list to store all pages\n",
    "pages = []\n",
    "\n",
    "# Loop through each manual and load its pages\n",
    "for manual_path in file_paths:\n",
    "    loader = PyPDFLoader(manual_path)\n",
    "    pages1 = loader.load_and_split()\n",
    "    pages.extend(pages1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "chunk_size = 4096\n",
    "docs_new = []\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    ")\n",
    "\n",
    "for doc in pages:\n",
    "    if len(doc.page_content) < chunk_size:\n",
    "        docs_new.append(doc)\n",
    "    else:\n",
    "        docs = text_splitter.create_documents([doc.page_content])\n",
    "        docs_new.extend(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 197 embeddings in 1 batches of size 197:: 100%|██████████| 1/1 [00:10<00:00, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://siddartha10/manufacturing_CSI', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape      dtype  compression\n",
      "  -------    -------     -------    -------  ------- \n",
      "   text       text      (197, 1)      str     None   \n",
      " metadata     json      (197, 1)      str     None   \n",
      " embedding  embedding  (197, 1536)  float32   None   \n",
      "    id        text      (197, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "docs = db.add_documents(docs_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain.chains.openai_functions import (\n",
    "    create_structured_output_chain,\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset docs and ids if they exist (optional you can also ingest)\n",
    "docs = db.vectorstore.dataset.text.data(fetch_chunks=True, aslist=True)[\"value\"]\n",
    "ids = db.vectorstore.dataset.id.data(fetch_chunks=True, aslist=True)[\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a world class expert for generating questions based on provided context.                 You make sure the question can be answered by the text.\n",
      "Human: Use the given text to generate a question from the following input: \n",
      "UWM CSI Vial Filling Connected Smart Manufacturing (CSM) System The UWM CSI Vial Filling CSM  System is an intelligent manufacturing system using the latest Industry 4.0 connected advanced manufacturing equipment and techniques to produce  vials filled with varying product using a variety of filling methods and capturing process data that can be used for data analysis and system optimization.  The  Vial Filling CSM System is a platform that university faculty and students will use for both education and research to  further the advancement of a connected enterprise.   The CAM components are  integrate d seamlessly within a fully  integrated architecture and connected  enterprise using cutting -edge smart -data devices at all layers.     The process overview detailed in this section describes in general how the Vial Filling Connected Smart Manufacturing system functions as a complete system processing components.  Operational steps and slight variances in the process may differ from what is described here depending on the configuration parameters or  using the stations  in a dry cycle mode .  The Vial Filling CSM utilizes localized system configuration setting within the machine as well as process data requirements and parameters to determine how  to process the product and which stations and inspections are required to complete the production job.  When running under MES Production Center control, the process requirements and parameters are received  from the MES system as to where  and how to process and inspect the vials produced by the system .    \n",
      "Human: Tips: Make sure to answer in the correct format\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "question='What is the purpose of the UWM CSI Vial Filling Connected Smart Manufacturing (CSM) System?'\n"
     ]
    }
   ],
   "source": [
    "# If we pass in a model explicitly, we need to make sure it supports the OpenAI function-calling API.\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "class Questions(BaseModel):\n",
    "    \"\"\"Identifying information about the manufacturing system.\"\"\"\n",
    "\n",
    "    question: str = Field(..., description=\"Questions about manufacturing system\")\n",
    "\n",
    "\n",
    "prompt_msgs = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a world class expert for generating questions based on provided context. \\\n",
    "                You make sure the question can be answered by the text.\"\n",
    "    ),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "        \"Use the given text to generate a question from the following input: {input}\"\n",
    "    ),\n",
    "    HumanMessage(content=\"Tips: Make sure to answer in the correct format\"),\n",
    "]\n",
    "prompt = ChatPromptTemplate(messages=prompt_msgs)\n",
    "chain = create_structured_output_chain(Questions, llm, prompt, verbose=True)\n",
    "\n",
    "text = \"\"\"\n",
    "UWM CSI Vial Filling Connected Smart Manufacturing (CSM) System The UWM CSI Vial Filling CSM  System is an intelligent manufacturing system using the latest Industry 4.0 connected advanced manufacturing equipment and techniques to produce  vials filled with varying product using a variety of filling methods and capturing process data that can be used for data analysis and system optimization.  The  Vial Filling CSM System is a platform that university faculty and students will use for both education and research to  further the advancement of a connected enterprise.   The CAM components are  integrate d seamlessly within a fully  integrated architecture and connected  enterprise using cutting -edge smart -data devices at all layers.     The process overview detailed in this section describes in general how the Vial Filling Connected Smart Manufacturing system functions as a complete system processing components.  Operational steps and slight variances in the process may differ from what is described here depending on the configuration parameters or  using the stations  in a dry cycle mode .  The Vial Filling CSM utilizes localized system configuration setting within the machine as well as process data requirements and parameters to determine how  to process the product and which stations and inspections are required to complete the production job.  When running under MES Production Center control, the process requirements and parameters are received  from the MES system as to where  and how to process and inspect the vials produced by the system .    \"\"\"\n",
    "questions = chain.run(input=text)\n",
    "print(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [10:19<00:00,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_queries(docs: List[str], ids: List[str], n: int = 100):\n",
    "    questions = []\n",
    "    relevances = []\n",
    "    pbar = tqdm(total=n)\n",
    "    while len(questions) < n:\n",
    "        # 1. randomly draw a piece of text and relevance id\n",
    "        r = random.randint(0, len(docs) - 1)\n",
    "        text, label = docs[r], ids[r]\n",
    "\n",
    "        # 2. generate queries and assign and relevance id\n",
    "        generated_qs = [chain.run(input=text).question]\n",
    "        questions.extend(generated_qs)\n",
    "        relevances.extend([[(label, 1)] for _ in generated_qs])\n",
    "        pbar.update(len(generated_qs))\n",
    "        if len(questions) % 10 == 0:\n",
    "            print(f\"q: {len(questions)}\")\n",
    "    return questions[:n], relevances[:n]\n",
    "\n",
    "\n",
    "chain = create_structured_output_chain(Questions, llm, prompt, verbose=False)\n",
    "questions, relevances = generate_queries(docs, ids, n=200)\n",
    "\n",
    "train_questions, train_relevances = questions[:100], relevances[:100]\n",
    "test_questions, test_relevances = questions[100:], relevances[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "DeepMemoryWaitingListError",
     "evalue": "Deep Memory is available only for waiting list users. Please, follow the link and join the waiting list: https://www.deeplake.ai/deepmemory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDeepMemoryWaitingListError\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32m/Users/siddartha/Desktop/github/ActiveloopQA/deep_memory_code.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/siddartha/Desktop/github/ActiveloopQA/deep_memory_code.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m job_id \u001b[39m=\u001b[39m db\u001b[39m.\u001b[39;49mvectorstore\u001b[39m.\u001b[39;49mdeep_memory\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/siddartha/Desktop/github/ActiveloopQA/deep_memory_code.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     queries\u001b[39m=\u001b[39;49mtrain_questions,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/siddartha/Desktop/github/ActiveloopQA/deep_memory_code.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     relevance\u001b[39m=\u001b[39;49mtrain_relevances,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/siddartha/Desktop/github/ActiveloopQA/deep_memory_code.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/deeplake/core/vectorstore/deep_memory/deep_memory.py:52\u001b[0m, in \u001b[0;36maccess_control.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     51\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         \u001b[39mraise\u001b[39;00m DeepMemoryWaitingListError()\n\u001b[1;32m     53\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;31mDeepMemoryWaitingListError\u001b[0m: Deep Memory is available only for waiting list users. Please, follow the link and join the waiting list: https://www.deeplake.ai/deepmemory"
     ]
    }
   ],
   "source": [
    "job_id = db.vectorstore.deep_memory.train(\n",
    "    queries=train_questions,\n",
    "    relevance=train_relevances,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
